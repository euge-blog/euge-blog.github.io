<!DOCTYPE html>



<html lang="en-US" 
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

    

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="How can we build an artificial brain from our knowledge of the human brain?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How can we build an artificial brain from our knowledge of the human brain?" />
<meta property="og:description" content="How can we build an artificial brain from our knowledge of the human brain?" />
<link rel="canonical" href="http://localhost:4000/2022/10/19/build-brain.html" />
<meta property="og:url" content="http://localhost:4000/2022/10/19/build-brain.html" />
<meta property="og:site_name" content="Eugenio Culurciello Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-19T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How can we build an artificial brain from our knowledge of the human brain?" />
<meta name="twitter:site" content="@culurciello" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-19T00:00:00-04:00","datePublished":"2022-10-19T00:00:00-04:00","description":"How can we build an artificial brain from our knowledge of the human brain?","headline":"How can we build an artificial brain from our knowledge of the human brain?","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2022/10/19/build-brain.html"},"url":"http://localhost:4000/2022/10/19/build-brain.html"}</script>
<!-- End Jekyll SEO tag -->


  <title>How can we build an artificial brain from our knowledge of the human brain? | Eugenio Culurciello Blog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png">
<link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'>
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">




  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/post.min.js"></script>






</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" alt="avatar" class="mx-auto">
        
        <img src="/assets/logo.jpeg" alt="avatar" onerror="this.style.display='none'">
      </a>
    </div>

    <div class="site-title mt-3">
      <a href="/">Eugenio Culurciello Blog</a>
    </div>

    <div class="site-subtitle font-italic">Eugenio Culurciello Blog</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    
      

      
      <a href="https://github.com/culurciello" aria-label="github"
        class="order-3"
        target="_blank" rel="noopener">
        <i class="fab fa-github-alt"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/culurciello" aria-label="twitter"
        class="order-4"
        target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['culurciello','gmail.com'].join('@')" aria-label="email"
        class="order-5"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        class="order-6"
        >
        <i class="fas fa-rss"></i>
      </a>
      

    

    
      
        <span class="icon-border order-2"></span>
      

      <span id="mode-toggle-wrapper" class="order-1">
        <!--
  Switch the mode between dark and light.
-->

<i class="mode-toggle fas fa-adjust"></i>

<script type="text/javascript">

  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      var self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addListener(function() {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.updateMermaid();
      });

    } /* constructor() */


    setDark() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_KEY);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer) ) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    updateMermaid() {
      if (typeof mermaid !== "undefined") {
        let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default");
        let config = { theme: expectedTheme };

        /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function() {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }

        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }

      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.updateMermaid();

    } /* flipMode() */

  } /* ModeToggle */

  let toggle = new ModeToggle();

  $(".mode-toggle").click(function() {

    toggle.flipMode();

  });

</script>

      </span>
    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper" class="row justify-content-center topbar-down">
  <div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between">
    <span id="breadcrumb">

    

    

      

        
          

        

      

        
        <span>
          
          
          <a href="/2022">
            2022
          </a>
        </span>

        

      

        
        <span>
          
          
          <a href="/10">
            10
          </a>
        </span>

        

      

        
        <span>
          
          
          <a href="/19">
            19
          </a>
        </span>

        

      

        
          <span>How can we build an artificial brain from our knowledge of the human brain?</span>

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" placeholder="Search...">
      <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i>
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




  

  

  <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->
  
  

  

  



<!-- return -->
<div class="row">

  <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">

    <div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

      <h1 data-toc-skip>How can we build an artificial brain from our knowledge of the human brain?</h1>

      <div class="post-meta text-muted d-flex flex-column">
        <!-- Published date and author -->
        <div>
          <span class="semi-bold">
            Eugenio Culurciello
          </span>
          <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Oct 19, 2022, 12:00 AM -0400"
  

  
  prep="on" >

  
  

  
    Oct 19, 2022
  

  <i class="unloaded">2022-10-19T00:00:00-04:00</i>

</span>

        </div>

        <div>
          <!-- lastmod -->
          

          <!-- read time -->
          <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2671 words">14 min</span>


          <!-- page views -->
          

        </div>

      </div> <!-- .post-meta -->

      <div class="post-content">

        

        <h1 id="how-can-we-build-an-artificial-brain-from-our-knowledge-of-the-human-brain">How can we build an artificial brain from our knowledge of the human brain?</h1>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2022-10-19-build-brain/1*vajK8QkTrcG1EKAt6HXEEA.jpeg" alt="" /></p>

<p>I have been excited about reproducing the human brain in hardware and software since I read an article on neuromorphic engineering in the mid 1990s. I read much about neuroscience and psychology and of course machine learning algorithms, always with the goal of creating an artificial brain that can sense and understand the world as we humans do, or better, hopefully way better one day!</p>

<p>After several years, I got frustrated when I found out that we are unable to understand the brain wiring and activity of enough neurons to really be able to reverse-engineer it. When I think about ideas and a framework to replicate the brain in software, all we have today is a growing number of ideas and experiments and conjectures and even grand visions, but nothing that is unified and cohesive, and even less on a potential strategy to tackle this problem.</p>

<p>On the other hand, machine learning has progressed enormously in the last 10–15 years, guided by the same goals of replicating human abilities in computing machines. 15 years ago we were dreaming of identifying a human being, their posture, their actions from a camera view. Today this is only too easy! 15 years ago we were dabbling with probabilistic chains trying to unravel written human language. Today we have conversational systems that can almost pass for fellow humans. By the way, with “machine learning algorithm” here in this post I am referring to “neural networks”.</p>

<p>And indeed neuroscience and psychology have been a major inspiration for machine learning, even when not enough is known about our human brain, much can be tested and tried out with computer algorithms. And so it goes, 10 years of endless trials and errors, an evolution of machine learning algorithms trying not to necessarily reverse engineer the brain, as much as trying to adapt all our ideas to solving the problem of learning with algorithms. This is a  <em>key point,</em> while there are religious faction trying to copy exactly the human brain with certified “brain approved” branding, the goal of many other has simply been: let us use any knowledge we have to engineer an artificial brain, be that a good model of our human brain or not!</p>

<p>Here I want to describe a framework for intelligence and learning that I call “<strong>Mix-Match</strong>”. Mix-Match is an algorithm and knowledge acquisition framework that is scalable and can explain how one could design the core knowledge graph acquisition in an artificial brain.</p>

<p>First I will describe what artificial and real brain concepts are the foundation of Mix-Match below. I will describe how artificial and real learning are similar (together) or different (apart).</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2022-10-19-build-brain/1*VHIV0xsJVlixYtn1IDXdxA.gif" alt="" /></p>

<h1 id="together">Together</h1>

<p>Yet I can see there are many really strong ideas from neuroscience and psychology that are one of the fundamental reason why machine learning got so good recently. I will discuss some with you below.</p>

<h2 id="neural-networks">Neural networks</h2>

<p>Well hello! Neural networks are at the core of machine learning today, powering the most sophisticated learning machines we have! Artificial neural networks or ANN, as they called them, are real-valued output neurons that are modeled after biological neurons. They are the fundamental building block of computation and memory in the brain, both real and artificial. They have the ability to take multiple inputs weighted by learned kernels, and can the combine them into a non-linear output. Non-linearity is important to create any complex functions, and possibly unavoidable in real brains.</p>

<h2 id="feed-forward-visual-system">Feed-forward visual system</h2>

<p>Neural networks are what they are today because of many people, but if I had to pick a moment it would be because of the work of Yann LeCun in mid 1990s, where they devised a model of the human visual processing system in the form of LeNet5, the very first convolutional neural network. This network was used to learn to identify handwritten characters, and was a breakthrough not only because of its architecture, but also because it advanced gradient descent learning techniques, the core of most machine learning today. LeNet5 was modeled after the mammalian visual system processing information via simple and them more and more complex cells, extracting a hierarchy of information. LeNet5, gradient-descent, and their ability to learn and perform inspired the artificial neural network revolution of the 2010s — today.</p>

<h2 id="cortex-and-micro-columns">Cortex and micro-columns</h2>

<p>One of the most delightful ideas is that the human neocortex is composed of the same basic circuit repeated ad libitum: the cortical micro-circuit. It does make sense to some extent: the neocortex is a flat disk of 2–4 mm of tissue, and it structure seems to be composed on many “micro columns”.</p>

<p>In terms of neural circuit connectivity, these micro-columns are a few layers deep, say 6, but definitely not very deep like some modern neural networks. One can thus think of a “shallow” network that is well connected to a large number of similar units.</p>

<p>What really inspired me about cortical micro-circuits is not just that we could break down understanding of the neocortex into a smaller step: understanding the columns. But also it reminded me of many processes in parallel requiring the concept of “attention” to sort them into useful bits.</p>

<h2 id="attention">Attention</h2>

<p>Attention is a key concept in psychology and neuroscience because it is the process that allow us to focus on some information that is important rather than other information that is not.</p>

<p>Attention in neural networks arrived later than we expected, say in around year ~2016. In reality any neural network performs attention: because the weights are in fact selecting specific signals from an array of inputs.</p>

<p>But really the key innovation in artificial neural networks arrived with the Transformer model in 2017. This model was using attention for almost everything, and it inspired the use of neural attention for many tasks, starting from natural language processing to vision and more.</p>

<p>If you look at the neural attention circuit with attention (pun intended!) you will notice it may very well be a good approximate model of cortical column circuitry. Its multi-headed attention module, in particular, is a good suitable model of how a column would process information, and find connection between sets of data. Of course it is not a 1–1 model comparison, it will never be! But to me it resonates: artificial neural attention == cortical columns.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2022-10-19-build-brain/1*Cix0nMSHYyphJbURI9qjlQ.png" alt="" /></p>

<h1 id="apart">Apart</h1>

<p>And there are many areas in which biological and artificial learning differ. After all why should they be the same, they are based on completely different foundational computing substrates (technologies?).</p>

<h2 id="learning">Learning</h2>

<p>Learning algorithms in artificial and real neural networks are clearly different. They are different in learning algorithms, continual capabilities, scope and architecture.</p>

<p>Artificial neural network use back-propagation and gradient descent algorithms to learn from examples. Back-propagation creates an error data-point at the output of a neural network, and that error is then used an propagated back throughput the network to adapt neural weights. Real neural network learning algorithms are not well understood, and often it is referred to Hebbian learning as a potential candidate. Hebbian learning works like this: it strongly connects neurons that fire in short succession, and depresses connections that happen non-causally or long after a cell spikes. It is normal that learning algorithms can differ, after all real and artificial neurons live in different media, with different characteristics and opportunities. If artificial network can use metal and well-insulated circuits to propagate signal farther away than real ones, then why not use that ability?</p>

<p>Continual learning is the ability to continue to learn at every instant and retain previous important information. So far we are in the dark on how to achieve this in artificial neural networks, and it has to do with the current supervised learning algorithms we use. I suspect that large-scale contrastive techniques, for example, have the ability to learn continuously — but in a world where they are stimulated by constant inputs and examples of all kinds. A bit like us on a daily basis. We do not yet know how to achieve the continual and life-long learning that powers our real brains, but we have an opportunity to keep searching and exploring a way to do so. This opportunity is Mix-Match, as described below. This new knowledge gathering architecture can in fact continue to learn indefinitely.</p>

<p>Scope and architecture of artificial neural network cannot yet take advantage or billions of years of evolution, and so machine learning researchers are left with the tedious search by trials and errors. This is a depressing proposal, but let us face the facts: we really do not yet know how to connect these artificial blocks to create anything intelligent of capable or solving multiple tasks and learning continuously, but Mix-Match can help, as we will see below. But one positive comes out of this: it allows us to refine and define the blocks that are most promising and create neural architectures that can solve low-hanging fruits. And we have done this for the last 10 years, slowly creating neural networks that conquered image categorization, natural speech and textual language, photo-realistic image creation, playing Go and other games, driving your car. Sure they are all disparate neural networks that only work on one task each, and we do need to work further on multi-modal, multi-tasks networks. The real issues there is that creatures are embodied in a set of sensors and physical configuration, and our neural networks are still living without a body, most incapable of movement, still residing inside our computer processors. This is a huge limitation to learning opportunities also due to the fact that we are far from being able to devise an artificial brain for artificial embodies entities (robots). Maybe the closest example we have today is an autonomous car — an opportunity!</p>

<h2 id="inhibition">Inhibition</h2>

<p>Real neurons use inhibition to depress the activity of neighbors and inhibitory neurons outputs are in fact a vast majority of a neurons outputs. This is due to the fact that spiking neurons cannot output negative values, as negative spike rates do not make sense. Instead, artificial neural networks  <em>can</em>  have negative outputs due to the range of the output numerical format and precision.</p>

<h2 id="spiking"><strong>Spiking</strong></h2>

<p>Real neurons spike because that is the best way to send signal across many centimeters of leaky goo. Evolution discovered that cells that can spike are able to communicate to many more neurons and thus allow attention networks to be more efficient and process a much larger amount of data. Instead artificial neurons live in silicon and metal, and their conductors are well insulated, to the point that even sending analog voltages over many centimeters is possible. And digital neurons are even better: they can transmit data without errors across the world and to far space! So there we go — we will use this ability and do away with pulsating neural networks!</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2022-10-19-build-brain/1*qHwpzm3sLAsoTdB0rIBmMA.jpeg" alt="" /></p>

<h1 id="joining-forces-mix-match">Joining Forces: Mix-Match</h1>

<p>In my opinion, the the concept that connects both artificial and real brains and has the potential to be a key ingredient to building brains and intelligence, is the concept of attention and learning to co-locate knowledge nuggets or events — I call this architecture  <strong>Mix-Match</strong>.</p>

<p>I mentioned above that multi-headed attention is the circuit we can use to address multiple applications. In fact today, artificial neural attention a la Transformer is the closest we have to an universal neural network architecture that can make sense of heterogeneous types of data. It is in fact an architecture that addresses: text, speech and vision together in one unified neural processing solution. Artificial neural attention is maybe the neural architecture diagram that comes closer to cortical columns, as it represents a  <em>lego-block</em>  of artificial neural architecture, one that replicates in the same way that our cortex is composed of many many cortical micro-circuits. Artificial neural attention is the building block of a large artificial brain that uses the same principle to sense and process all kinds of information, abstracting away the sensing domain and the format of the inputs data, and rather focusing on understanding it and correlating it that what is already known. In fact attention is a way to identifying inputs by locating them in our knowledge space, a space designed and constructed by co-locating data!</p>

<p><strong>Mix-Match</strong>  is in my opinion the best theory of the brain and intelligence we have today. This framework is still in development and is still highly speculative, but it is important to mention it early on so we can later claimed we predicted the future! Co-locating information is simply connecting information that occurs close in space or time in the same space. It is like giving it a “name” in language. Imagine an “event” where you see a person stomping their foot and making a peculiar noise. And suppose someone observes this and says “they are stomping!” Now in the Mix-Match co-locating space, all three events: (1) the noise, (2) the video feed and (3) the words uttered because of the event will all combine into a tight embedding space. now we have co-located three sensing modalities into one. Suppose you do this for all experiences in your life, all data you ever come to sense or perceive.</p>

<blockquote>
  <p>This is Mix-Match!</p>
</blockquote>

<p>It is a simple learning architecture where knowledge is aggregates in its raw multi-modality, and where all components of any knowledge events come together. Modalities  <em>Mix</em>  and then are  <em>Matched</em>  to form a specific point in the embedding space.</p>

<p>Mix-Match is a core ingredient for an artificial brain. It is the foundation on top of which multiple abilities can arise. It supports the development of complex learning connecting the myriad of events that we witness in our lives, and can illustrate how we interlink experiences across sensory modalities, space and time.</p>

<p>A summary of Mix-Match properties are:</p>

<ul>
  <li>A common architecture for all data and knowledge — based on a large scale attention architecture</li>
  <li>Continual learning is part of this system — since it expands the embedding space to include all new events without erasing previous ones</li>
  <li>Application can be supervised — learning of abilities on top of the knowledge graph is a matter of connecting examples to points in the embedded space</li>
</ul>

<h1 id="final-words">Final words</h1>

<p>I hope this inspires you to build an artificial brain and learn all you can from our existing brain. There is no need to refute artificial neural networks today because they are not what we want, or as capable as our brain. Also there is no need to worry if we are unable to study our own brain today, if we do not have the tools or the ability to spy inside many many neurons as we go about our day. One day we will — maybe with Mix-Match. Maybe you can help us on that front!</p>

<h1 id="references">References:</h1>

<p>Just a few references here, as they are too many.</p>

<p><a href="https://ieeexplore.ieee.org/document/490055"></a></p>

<h2 id="neuromorphic-vision-chips">Neuromorphic vision chips</h2>

<h3 id="analog-circuits-based-on-resistive-networks-emulate-the-behavior-of-the-vertebrate-eye-detecting-edges">Analog circuits based on resistive networks emulate the behavior of the vertebrate eye, detecting edges…</h3>

<p>ieeexplore.ieee.org</p>

<p><a href="https://numenta.com/resources/on-intelligence/"></a></p>

<h2 id="on-intelligence-book-by-jeff-hawkins">On Intelligence (Book) by Jeff Hawkins</h2>

<h3 id="reviews--press-jeff-hawkins-and-on-intelligence-are-featured-in-fortune-magazine---written-by-david-stipp-how-do-you">Reviews &amp; Press Jeff Hawkins and On Intelligence are featured in Fortune Magazine - written by David Stipp How Do You…</h3>

<p>numenta.com</p>

<p><a href="https://www.goodreads.com/en/book/show/940331.From_Neuron_to_Brain"></a></p>

<h2 id="from-neuron-to-brain">From Neuron to Brain</h2>

<h3 id="the-best-parts-were-much-better-than-the-best-parts-of-the-cell-a-molecular-approach-while-the-worst-parts-were-worse">the best parts were much better than the best parts of The Cell: A Molecular Approach, while the worst parts were worse…</h3>

<p>www.goodreads.com</p>

<p><a href="https://www.penguinrandomhouse.com/books/655682/vision-science-by-stephen-e-palmer/"></a></p>

<h2 id="vision-science-by-stephen-e-palmer-9780262161831--penguinrandomhousecom-books">Vision Science by Stephen E. Palmer: 9780262161831 | PenguinRandomHouse.com: Books</h2>

<h3 id="get-the-latest-updates-about-stephen-e-palmer-and-go-from-well-read-to-best-read-with-book-recs-deals-and-more-in">Get the latest updates about Stephen E. Palmer And go from well-read to best read with book recs, deals and more in…</h3>

<p>www.penguinrandomhouse.com</p>

<p><a href="https://arxiv.org/abs/1706.03762"></a></p>

<h2 id="attention-is-all-you-need">Attention Is All You Need</h2>

<h3 id="the-dominant-sequence-transduction-models-are-based-on-complex-recurrent-or-convolutional-neural-networks-in-an">The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an…</h3>

<p>arxiv.org</p>

<p><a href="https://arxiv.org/abs/2106.14413"></a></p>

<h2 id="co2l-contrastive-continual-learning">Co$^2$L: Contrastive Continual Learning</h2>

<h3 id="recent-breakthroughs-in-self-supervised-learning-show-that-such-algorithms-learn-visual-representations-that-can-be">Recent breakthroughs in self-supervised learning show that such algorithms learn visual representations that can be…</h3>

<p>arxiv.org</p>

<h1 id="about-the-author">About the author</h1>

<p>I have almost 20 years of experience in neural networks in both hardware and software (a rare combination). See about me here:  <a href="https://medium.com/@culurciello/">Medium</a>,  <a href="https://culurciello.github.io/">webpage</a>,  <a href="https://scholar.google.com/citations?user=SeGmqkIAAAAJ">Scholar</a>,  <a href="https://www.linkedin.com/in/eugenioculurciello/">LinkedIn</a>, and more…</p>

<p>If you found this article useful, please consider a  <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=Q3FHE3BWSC72W">donation</a>  to support more tutorials and blogs. Any contribution can make a difference!</p>


      </div>

      <div class="post-tail-wrapper text-muted">

        <!-- categories -->
        

        <!-- tags -->
        

        <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
          
          <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
          </div>
          

          <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=How can we build an artificial brain from our knowledge of the human brain? - Eugenio Culurciello Blog&url=http://localhost:4000/2022/10/19/build-brain.html" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=How can we build an artificial brain from our knowledge of the human brain? - Eugenio Culurciello Blog&u=http://localhost:4000/2022/10/19/build-brain.html" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://telegram.me/share?text=How can we build an artificial brain from our knowledge of the human brain? - Eugenio Culurciello Blog&url=http://localhost:4000/2022/10/19/build-brain.html" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>

  </span>
</div>


        </div><!-- .post-tail-bottom -->

      </div><!-- div.post-tail -->

    </div> <!-- .post -->


  </div> <!-- #post-wrapper -->

  

  

  <!--
  The Pannel on right side (Desktop views)
-->

<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">

  <div class="access">

  














  

  

















  
  </div> <!-- .access -->

  

</div> <!-- #panel-wrapper -->


</div> <!-- .row -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8">
    <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->




  
    
    
      
      
        
        
        
      
    
  
    
    
      
      
        
        
        
      
    
  
    
    
      
      
        
        
        
          





  <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
    <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/2025/01/03/AI-in-2025.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Jan  3
  

  <i class="unloaded">2025-01-03T00:00:00-05:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Artificial Intelligence, AI in 2025 and beyond</h3>
            <div class="text-muted small">
              <p>
                





                Artificial Intelligence, AI in 2025 and beyond

SOME THOUGHTS…

We are reaching the second quarter of the 21st century: it is an exciting milestone. I have been in “adult” life in the last 25 years...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/2024/12/17/what-about-my-hair.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Dec 17, 2024
  

  <i class="unloaded">2024-12-17T00:00:00-05:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>What about my hair?</h3>
            <div class="text-muted small">
              <p>
                





                What about my hair?

For all the advances in technology and all the promises of space exploration I still think we are behind in our understanding of life and our own abilities.

For decades we tal...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/2024/10/31/llm-use-cases.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Oct 31, 2024
  

  <i class="unloaded">2024-10-31T00:00:00-04:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Insights into the use of Generative AI systems</h3>
            <div class="text-muted small">
              <p>
                





                Insights into the use of Generative AI systems

Generative AI models, such as large language models (LLMs), have demonstrated remarkable capabilities in mimicking human-like communication. We here ...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->



    <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/2022/09/23/data-bundles-together.html" class="btn btn-outline-primary"
    prompt="Older">
    <p>Data that bundles together, is learned together</p>
  </a>
  

  
  <a href="/2022/11/09/drop-the-dataset.html" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Drop the dataset</p>
  </a>
  

</div>


    

    </div> <!-- #post-extend-wrapper -->

  </div> <!-- .col-* -->

</div> <!-- .row -->



  <!--
  image lazy load: https://github.com/ApoorvSaxena/lozad.js
-->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>

<script type="text/javascript">
  const imgs = document.querySelectorAll('.post-content img');
  const observer = lozad(imgs);
  observer.observe();
</script>




        <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2025
          <a href="https://twitter.com/culurciello">Eugenio Culurciello</a>.
          <!--  -->
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">

          <!--Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>. -->
        </p>
      </div>
    </div>
  </div>
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      

















      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="http://localhost:4000{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


  </body>

</html>

