<!DOCTYPE html>



<html lang="en-US" 
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

    

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Artificial Intelligence in 2019" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Artificial Intelligence in 2019" />
<meta property="og:description" content="Artificial Intelligence in 2019" />
<link rel="canonical" href="http://localhost:4000/2018/12/21/AI-in-2019.html" />
<meta property="og:url" content="http://localhost:4000/2018/12/21/AI-in-2019.html" />
<meta property="og:site_name" content="Eugenio Culurciello Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-21T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Artificial Intelligence in 2019" />
<meta name="twitter:site" content="@culurciello" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2018-12-21T00:00:00-05:00","datePublished":"2018-12-21T00:00:00-05:00","description":"Artificial Intelligence in 2019","headline":"Artificial Intelligence in 2019","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/12/21/AI-in-2019.html"},"url":"http://localhost:4000/2018/12/21/AI-in-2019.html"}</script>
<!-- End Jekyll SEO tag -->


  <title>Artificial Intelligence in 2019 | Eugenio Culurciello Blog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png">
<link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'>
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">




  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/post.min.js"></script>






</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" alt="avatar" class="mx-auto">
        
        <img src="/assets/logo.jpeg" alt="avatar" onerror="this.style.display='none'">
      </a>
    </div>

    <div class="site-title mt-3">
      <a href="/">Eugenio Culurciello Blog</a>
    </div>

    <div class="site-subtitle font-italic">Eugenio Culurciello Blog</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    
      

      
      <a href="https://github.com/culurciello" aria-label="github"
        class="order-3"
        target="_blank" rel="noopener">
        <i class="fab fa-github-alt"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/culurciello" aria-label="twitter"
        class="order-4"
        target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['culurciello','gmail.com'].join('@')" aria-label="email"
        class="order-5"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        class="order-6"
        >
        <i class="fas fa-rss"></i>
      </a>
      

    

    
      
        <span class="icon-border order-2"></span>
      

      <span id="mode-toggle-wrapper" class="order-1">
        <!--
  Switch the mode between dark and light.
-->

<i class="mode-toggle fas fa-adjust"></i>

<script type="text/javascript">

  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      var self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addListener(function() {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.updateMermaid();
      });

    } /* constructor() */


    setDark() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_KEY);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer) ) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    updateMermaid() {
      if (typeof mermaid !== "undefined") {
        let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default");
        let config = { theme: expectedTheme };

        /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function() {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }

        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }

      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.updateMermaid();

    } /* flipMode() */

  } /* ModeToggle */

  let toggle = new ModeToggle();

  $(".mode-toggle").click(function() {

    toggle.flipMode();

  });

</script>

      </span>
    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper" class="row justify-content-center topbar-down">
  <div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between">
    <span id="breadcrumb">

    

    

      

        
          

        

      

        
        <span>
          
          
          <a href="/2018">
            2018
          </a>
        </span>

        

      

        
        <span>
          
          
          <a href="/12">
            12
          </a>
        </span>

        

      

        
        <span>
          
          
          <a href="/21">
            21
          </a>
        </span>

        

      

        
          <span>Artificial Intelligence in 2019</span>

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" placeholder="Search...">
      <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i>
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




  

  

  <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->
  
  

  

  



<!-- return -->
<div class="row">

  <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">

    <div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

      <h1 data-toc-skip>Artificial Intelligence in 2019</h1>

      <div class="post-meta text-muted d-flex flex-column">
        <!-- Published date and author -->
        <div>
          <span class="semi-bold">
            Eugenio Culurciello
          </span>
          <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Fri, Dec 21, 2018, 12:00 AM -0500"
  

  
  prep="on" >

  
  

  
    Dec 21, 2018
  

  <i class="unloaded">2018-12-21T00:00:00-05:00</i>

</span>

        </div>

        <div>
          <!-- lastmod -->
          

          <!-- read time -->
          <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2534 words">14 min</span>


          <!-- page views -->
          

        </div>

      </div> <!-- .post-meta -->

      <div class="post-content">

        

        <h1 id="artificial-intelligence-in-2019">Artificial Intelligence in 2019</h1>

<h2 id="or-how-machine-learning-is-evolving-into-ai"><em>Or how machine learning is evolving into AI</em></h2>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2018-12-21-AI-in-2019/1*rCoo-qt4mrsIOVtZ7muLOg.jpeg" alt="" /></p>

<p>These are my opinions on where deep neural network and machine learning is headed in the larger field of artificial intelligence, and how we can get more and more sophisticated machines that can help us in our daily routines.</p>

<p>Please note that these are not predictions of forecasts, but more a detailed analysis of the trajectory of the fields, the trends and the technical needs we have to achieve useful artificial intelligence.</p>

<p>We will also examine low-hanging fruits, such as applications we can develop and promote today!</p>

<h1 id="goals">Goals</h1>

<p>The goal of the field is to produce machines with beyond-human abilities. Autonomous vehicles, smart homes, artificial assistants, security cameras are a first target. Home cooking and cleaning robots are a second target, together with surveillance drones and robots. Another one is assistants on mobile devices or always-on assistants. Another is full-time companion assistants that can hear and see what we experience in our life. One ultimate goal is a fully autonomous synthetic entity that can behave at or beyond human level performance in everyday tasks.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2018-12-21-AI-in-2019/1*rD2s5901_M8qENMlG6qA_w.jpeg" alt="" /></p>

<h1 id="software">Software</h1>

<p>Software is defined here as neural networks architectures trained with an optimization algorithm to solve a specific task.</p>

<p>Today neural networks are the de-facto tool for learning to solve tasks that involve <a href="https://medium.com/@culurciello/analysis-of-deep-neural-networks-dcf398e71aae">learning supervised to categorize</a>  from a large dataset.</p>

<p>But this is not artificial intelligence, which requires acting in the real world often learning without supervision and from experiences never seen before, often combining previous knowledge in disparate circumstances to solve the current challenge.</p>

<blockquote>
  <p>How do we get from the current neural networks to AI?</p>
</blockquote>

<p><strong>1- Neural network architectures</strong>  — when the field boomed, a few years back, we often said it had the advantage to learn the parameters of an algorithms automatically from data, and as such was superior to hand-crafted features.But we conveniently forgot to mention one little detail… the neural network architecture that is at the foundation of training to solve a specific task is not learned from data! In fact it is still designed by hand. Hand-crafted from experience, and it is currently one of the major limitations of the field.<a href="https://medium.com/@culurciello/analysis-of-deep-neural-networks-dcf398e71aae">Neural network architectures</a>  are the fundamental core of learning algorithms. Even if our learning algorithms are capable of mastering a new task, if the neural network is not correct, they will not be able to. But there is much activity in this area, and we reviewed it  <a href="https://towardsdatascience.com/learning-neural-network-architectures-6109cb133caf">here</a>.  The problem on learning neural network architecture from data is that it currently takes too long to experiment with multiple architectures on a large dataset.  One has to try training multiple architectures from scratch and see which one works best. Well this is exactly the time-consuming trial-and-error procedure we are using today! We ought to overcome this limitation and put more brain-power on this very important issue.</p>

<p><strong>2- Limitations of current neural networks</strong>  — We have talked about before on the limitation of neural networks as they are today. Cannot predict, reason on content, and have temporal instabilities —  we need a <em>new kind of neural networks</em> that you can about read <a href="https://medium.com/@culurciello/at-the-limits-of-learning-46122b99dfc5">here</a>.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="2018-12-21-AI-in-2019/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png" alt="Image result for encoder decoder neural network" /></p>

<p>Encoder-Decoder neural network</p>

<p>Connecting to the topic of the previous section, neural networks are evolving into encoder-decoders, where the encoder is a network that compresses data into a short code (representation) and the decoder is expanding that representation to generate another larger representation (think of these as generated images, mental simulations, highlights on an image as bounding boxes and segmentation masks). We have talked about how to use such networks to localize and detect key-points in images and video extensively  <a href="https://towardsdatascience.com/segmenting-localizing-and-counting-object-instances-in-an-image-878805fef7fc">here</a>; see also this  <a href="https://medium.com/@culurciello/analysis-of-deep-neural-networks-for-pixel-processing-i-3a71324fdc43">analysis</a>.  This is also the main ingredient in predictive neural networks  (more below).</p>

<p><strong>3- Unsupervised learning</strong>  — we cannot always be there for our neural networks, guiding them at every stop of their lives and every experience.  We cannot afford to correct them at every instance, and provide feedback on their performance.  We have our lives to live! But that is exactly what we do today with supervised neural networks: we offer help at every instance to make them perform correctly. Instead humans learn from just a handful of examples, and can self-correct and learn more complex data in a continuous fashion. We have talked about unsupervised learning extensively  <a href="https://medium.com/intuitionmachine/navigating-the-unsupervised-learning-landscape-951bd5842df9">here</a>.</p>

<p><strong>4- Predictive neural networks —</strong> A major limitation of current neural networks is that they do not possess one of the most important features of human brains: their predictive power. One major theory about how the human brain work is by constantly making predictions:  <a href="https://en.wikipedia.org/wiki/Predictive_coding">predictive coding</a>. If you think about it, we experience it every day. As you lift an object that you thought was light but turned out heavy. It surprises you, because as you approached to pick it up, you have predicted how it was going to affect you and your body, or your environment in overall.</p>

<p>Prediction allows not only to understand the world, but also to know when we do not, and when we should learn.  In fact we save information about things we do not know and surprise us, so next time they will not!  And  cognitive abilities are clearly linked to our attention mechanism in the brain: our innate ability to forego of 99.9% of our sensory inputs, only to focus on the very important data for our survival  — where is the threat and where do we run to to avoid it. Or, in the modern world, where is my cell-phone as we walk out the door in a rush.</p>

<p>Building predictive neural networks is at the core of interacting with the real world, and acting in a complex environment. As such this is the core network for any work in reinforcement learning. See more below.</p>

<p>We have talked extensively about the topic of predictive neural networks, and were one of the pioneering groups to study them and create them. For more details on predictive neural networks, see  <a href="https://towardsdatascience.com/a-new-kind-of-deep-neural-networks-749bcde19108">here</a>, and  <a href="https://medium.com/@culurciello/predictive-neural-networks-for-reinforcement-learning-490738725839">here</a>, and  <a href="https://towardsdatascience.com/adversarial-predictive-networks-3aa7026d53d2">here</a>.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2018-12-21-AI-in-2019/1*_ssa6fA__0MAJW_n_DALag.jpeg" alt="" /></p>

<p><strong>5- Continuous learning</strong>  — this is important because neural networks need to continue to learn new data-points continuously for their life. Current neural networks are not able to learn new data without being re-trained from scratch at every instance.  Neural networks need to be able to self-assess the need of new training and the fact that they do know something.  This is also needed to perform in real-life and for reinforcement learning tasks, where we want to teach machines to do new tasks without forgetting older ones. Continuous learning also ties in with  <em>transfer learning,</em> or how do we have these algorithms learn on their own by watching videos, just like we do when we want to learn how to cook something new? That is an ability that requires all the components we listed above, and also is important for reinforcement learning.</p>

<p>For more detail, see our  <a href="https://medium.com/@culurciello/continual-learning-da7995c24bca">summary of recent results</a>.</p>

<p><strong>6-</strong> <strong>Reinforcement learning</strong> <strong>—</strong> this is the holy grail of deep neural network research: teach machines how to learn to act in an environment, the real world! This requires self-learning, continuous learning, predictive power, and a lot more we do not know. There is much work in the field of reinforcement learning and we already talked about this  <a href="https://towardsdatascience.com/learning-and-performing-in-the-real-world-7e53eb46d9c3">here</a>  and more recently  <a href="https://medium.com/@culurciello/learning-and-performing-in-the-real-world-part-2-1fd3f393c2fd">here</a>.</p>

<p>Reinforcement learning is often  referred  as the “cherry on the cake”, meaning that it is just minor training on top of a plastic synthetic brain. But how can we get a “generic” brain that then solve all problems easily? It is a chicken-in-the-egg problem! Today to solve reinforcement learning problems, one by one, we use standard neural networks:</p>

<ul>
  <li>a deep neural network that takes large data inputs, like video or audio and compress it into representations</li>
  <li>a sequence-learning neural network, such as RNN, to learn tasks</li>
</ul>

<p>Both these components are what everyone uses because they are some of the  <a href="https://medium.com/@culurciello/neural-networks-building-blocks-a5c47bcd7c8d">available building blocks</a>. Still, results are unimpressive: yes we can learn to play video-games from scratch, and master fully-observable games like chess and go — this year even trained overnight! — but I do not need to tell you that is nothing compared to solving problems in a complex world and machines that can operate like us.</p>

<p>We believe that predictive neural networks are indispensable for reinforcement learning. Curiosity, as it is called today in the field! Stay tuned for more!</p>

<p><strong>8- No more recurrent neural networks</strong> —  <a href="https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0">recurrent neural network (RNN) are falling out of vogue</a>.  RNN are particularly bad at parallelizing for training and also slow even on special custom machines, due to their very high memory bandwidth usage — as such they are memory-bandwidth-bound, rather than computation-bound, see  <a href="https://medium.com/@culurciello/computation-and-memory-bandwidth-in-deep-neural-networks-16cbac63ebd5">here for more details</a>.  <a href="https://towardsdatascience.com/memory-attention-sequences-37456d271992">Attention based</a> and especially convolutional neural networks are more efficient and faster to train and deploy, and they suffer much less from scalability in training and deployment.</p>

<p><a href="https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0">We have already seen</a>  that convolutional and attention based neural network are going to slowly supplant speech recognition based on RNN, and also find their ways in reinforcement learning architecture and AI in general.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2018-12-21-AI-in-2019/1*9MoobKBFP8P-AkXT2vXOaw.jpeg" alt="" /></p>

<h1 id="hardware">Hardware</h1>

<p>Hardware for deep learning is at the core of progress. Let us now forget that the rapid expansion of deep learning in 2008–2012 and in the recent years is mainly due to hardware:</p>

<ul>
  <li>cheap image sensors in every phone allowed to collect huge datasets — yes helped by social media, but only to a second extent</li>
  <li>GPUs allowed to accelerate the training of deep neural networks</li>
</ul>

<p>And  <a href="https://towardsdatascience.com/hardware-for-deep-learning-8d9b03df41a">we have talked about hardware extensively before</a>. But we need to give you a recent update! In the last 2 years saw a boom in the are of machine learning hardware, and in particular on the one targeting deep neural networks. We have significant experience here, having designed 5 generations of deep neural network accelerators (see the most recent at  <a href="http://fwdnxt.com/">FWDNXT</a>).</p>

<p>There are several companies working in this space: NVIDIA (obviously), Intel, Nervana, Movidius, Bitmain, Cambricon, Cerebras, DeePhi, Google, Graphcore, Groq, Huawei, ARM, Wave Computing, etc.  All are developing custom high-performance micro-chips that will be able to train and run deep neural networks.</p>

<p>The key is to provide the lowest power and the highest measured performance while computing recent useful neural networks operations, not raw theoretical operations per seconds — as many claim to do.</p>

<p>But few people in the field understand how hardware can really change machine learning, neural networks and AI in general. And few understand what is important in micro-chips and how to develop them. A couple of ideas:</p>

<ul>
  <li>Architectures: many see computer architectures as just an array of multipliers and adders. But not all architectures are the same. Some better than others can minimize memory bandwidth and keep all units occupied at all times.</li>
  <li>Compilers: many think the hardware is not important, that a neural network compiler is the key. But when you design your own hardware, the compiler is just interpreting the neural network computational graph in optimized machine code.  Open-source compilers (many of which came out last year!) can only help so much, given that the most difficult step really depends on the secret architecture. While open-source compilers can be used as front-ends, there is still a lot of secret sauce at the intersection between hardware architecture and neural network graphs.</li>
  <li>Microchips: once an algorithm is important, the best way for optimizing performance per power is to make a custom microchip or ASIC or SoC. They can provide faster clocks and a smaller circuit area than FPGAs. FPGAs are including deep neural network accelerators now, expect them in 2019–2020, but microchips will always be better performers.</li>
  <li>Advances: there are several advances that will allow silicon deep neural network accelerators to gain 10–20x more performance per power easily, even if microchip scaling is not used. Look for advances in using lower numbers of bits, systems-on-a-package, advanced memories, to name a few.</li>
</ul>

<p>About neuromorphic neural networks hardware, please see  <a href="https://towardsdatascience.com/neuromorphic-and-spiking-or-not-894a836dc3b3">here</a>. A commentary on imitating real neural networks is  <a href="https://medium.com/@culurciello/biological-and-artificial-intelligence-23a5c65160e6">here</a>.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/2018-12-21-AI-in-2019/1*ovLnJ4l8g5J8s6lNKt3yww.jpeg" alt="" /></p>

<h1 id="applications">Applications</h1>

<p>We talked briefly about applications in the Goals section above, but we really need to go into details here. How is AI and neural network going to get into our daily life?</p>

<p>Here is our list:</p>

<ul>
  <li><strong>categorizing images and videos</strong>  — already here in many cloud services. The next steps are doing the same in smart camera feeds — also here today from many providers. Neural nets hardware will allow to remove the cloud and process more and more data locally: a winner for privacy and saving Internet bandwidth.</li>
  <li><strong>speech-based assistants</strong>  — they are becoming a part of our lives, as they play music and control basic devices in our “smart” homes. But dialogue is such a basic human activity, we often give it for granted. Small devices you can talk to are a  <em>revolution</em> that is happening right now. Speech-based assistants are getting better and better at serving us. But they are still tied to the power grid. The real assistant we want is moving with us. How about our cell-phone? Well again hardware wins here, because it will make that possible. Alexa and Cortana and Siri will be always on and always with you. Your phone will be your smart home — very soon. That is again another victory of the smart phone. But we also want it in our car and as we move around town. We need local processing of voice, and less and less cloud. More privacy and less bandwidth costs. Again hardware will give us all that in 1–2 years.</li>
  <li><strong>the real artificial assistants</strong>  — voice is great, but what we really want is something that can also see what we see. Analyze our environment as we move around. See an example  <a href="https://medium.com/@culurciello/shopper-artificial-intelligence-to-help-you-shop-d252bd995f78">here</a>  and ultimately  <a href="http://hyper-reality.co/">here</a>. This is the real AI assistant we can fall in love with. And neural network hardware will again grant your wish, as analyzing video feed is very computationally expensive, and currently at the theoretical limits on current silicon hardware. In other words a lot harder to do than speech-based assistants.But it is not impossible, and many smart startups like  <a href="https://www.aipoly.com/">AiPoly</a>already have all the software for it, but lack powerful hardware for running it on phones. Notice also that replacing the phone screen with a  <strong>wearable glasses-like device</strong>  will really make our assistant part of us!</li>
  <li><strong>the cooking robot</strong>  — the next biggest appliances will be a cooking and  <strong>cleaning robot</strong>. Here we may soon have the hardware, but we are clearly lacking the software. We need transfer learning, continuous learning and reinforcement learning. All working like a charm. Because you see: every recipe is different, every cooking ingredient looks different. We cannot hard-code all these options. We really need a  <strong>synthetic entity</strong>  that can learn and generalize well to do this. We are far from it, but not as far. Just a handful of years away at the current pace of progress. I sure will work on this, as I have done in the last few years~</li>
</ul>

<blockquote>
  <p>This blog post will evolve, like our algorithms and our machines. Please check it again soon.</p>
</blockquote>

<h1 id="about-the-author">About the author</h1>

<p>I have almost 20 years of experience in neural networks in both hardware and software (a rare combination). See about me here:  <a href="https://medium.com/@culurciello/">Medium</a>,  <a href="https://e-lab.github.io/html/contact-eugenio-culurciello.html">webpage</a>,  <a href="https://scholar.google.com/citations?user=SeGmqkIAAAAJ">Scholar</a>,  <a href="https://www.linkedin.com/in/eugenioculurciello/">LinkedIn</a>, and more…</p>


      </div>

      <div class="post-tail-wrapper text-muted">

        <!-- categories -->
        

        <!-- tags -->
        

        <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
          
          <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
          </div>
          

          <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=Artificial Intelligence in 2019 - Eugenio Culurciello Blog&url=http://localhost:4000/2018/12/21/AI-in-2019.html" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=Artificial Intelligence in 2019 - Eugenio Culurciello Blog&u=http://localhost:4000/2018/12/21/AI-in-2019.html" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://telegram.me/share?text=Artificial Intelligence in 2019 - Eugenio Culurciello Blog&url=http://localhost:4000/2018/12/21/AI-in-2019.html" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>

  </span>
</div>


        </div><!-- .post-tail-bottom -->

      </div><!-- div.post-tail -->

    </div> <!-- .post -->


  </div> <!-- #post-wrapper -->

  

  

  <!--
  The Pannel on right side (Desktop views)
-->

<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">

  <div class="access">

  














  

  

















  
  </div> <!-- .access -->

  

</div> <!-- #panel-wrapper -->


</div> <!-- .row -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8">
    <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->




  
    
    
      
      
        
        
        
      
    
  
    
    
      
      
        
        
        
      
    
  
    
    
      
      
        
        
        
          





  <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
    <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/2022/12/06/Drop-dataset-part-2.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Dec  6, 2022
  

  <i class="unloaded">2022-12-06T00:00:00-05:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Drop your dataset — part 2</h3>
            <div class="text-muted small">
              <p>
                





                Drop your dataset — part 2



In the previous post I have given some ideas on how we can overcome the limitation of current neural network training without using supervised datasets. I want to go i...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/2022/11/16/Why-filling-forms.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Nov 16, 2022
  

  <i class="unloaded">2022-11-16T00:00:00-05:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Why we fill our day by filling forms?</h3>
            <div class="text-muted small">
              <p>
                





                Why we fill our day by filling forms?



I do not know about you, but one of the worst way to spend time for me is  filling forms.

Yet it almost looks like we humans have evolved to hurt ourselves...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/2022/11/13/Clean-your-social-network.html">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Nov 13, 2022
  

  <i class="unloaded">2022-11-13T00:00:00-05:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Clean your social network</h3>
            <div class="text-muted small">
              <p>
                





                Clean your social network



Do you feel like your social network is not what it used to be? The messages and community you once enjoyed are not giving you the warm feeling they once did?


  it ma...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->



    <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/2018/12/09/bio-artificial-AI.html" class="btn btn-outline-primary"
    prompt="Older">
    <p>Biological and artificial intelligence</p>
  </a>
  

  
  <a href="/2019/04/15/sequence-to-sequence.html" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Sequence-to-sequence neural networks</p>
  </a>
  

</div>


    

    </div> <!-- #post-extend-wrapper -->

  </div> <!-- .col-* -->

</div> <!-- .row -->



  <!--
  image lazy load: https://github.com/ApoorvSaxena/lozad.js
-->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>

<script type="text/javascript">
  const imgs = document.querySelectorAll('.post-content img');
  const observer = lozad(imgs);
  observer.observe();
</script>




        <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2023
          <a href="https://twitter.com/culurciello">Eugenio Culurciello</a>.
          <!--  -->
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">

          <!--Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>. -->
        </p>
      </div>
    </div>
  </div>
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      

















      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="http://localhost:4000{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


  </body>

</html>

